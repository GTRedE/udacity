{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project 3: Behavioral Cloning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# import cv2\n",
    "import keras\n",
    "import keras.backend\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten, Lambda, Reshape\n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version:  2.0.6\n",
      "Tensorflow version:  1.2.1\n",
      "Keras backend:  tensorflow\n",
      "keras.backend.image_dim_ordering =  tf\n",
      "Backend ok\n"
     ]
    }
   ],
   "source": [
    "print('Keras version: ', keras.__version__)\n",
    "print('Tensorflow version: ', tf.__version__)\n",
    "print('Keras backend: ', keras.backend.backend())\n",
    "print('keras.backend.image_dim_ordering = ', keras.backend.image_dim_ordering())\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "if keras.backend.backend() != 'tensorflow':\n",
    "    raise BaseException(\"This script uses other backend\")\n",
    "else:\n",
    "    keras.backend.set_image_dim_ordering('tf')\n",
    "    print(\"\\nBackend OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/udacity/driving_log.csv', newline='') as f:\n",
    "    udacity_data = list(csv.reader(f, skipinitialspace=True, delimiter=',', quoting=csv.QUOTE_NONE))\n",
    "\n",
    "print('total rows: ', len(udacity_data))\n",
    "print(udacity_data[0])\n",
    "udacity_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "columns = udacity_data[0]\n",
    "udacity_df = pd.read_csv('data/udacity/driving_log.csv', skiprows=[0], names=columns)\n",
    "\n",
    "print('total rows: ', len(udacity_df))\n",
    "udacity_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Dataset Summary & Exploration\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Preview random set of images from each camera angle\n",
    "\n",
    "# Display visualizations in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(udacity_data))\n",
    "img_dir = 'data/udacity/'\n",
    "\n",
    "center_img = mpimg.imread(img_dir + udacity_data[index][0])\n",
    "left_img = mpimg.imread(img_dir + udacity_data[index][1])\n",
    "right_img = mpimg.imread(img_dir + udacity_data[index][2])\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot2grid((1, 3), (0, 0));\n",
    "plt.axis('off')\n",
    "plt.title('left camera')\n",
    "plt.imshow(left_img, cmap=\"gray\")\n",
    "\n",
    "plt.subplot2grid((1, 3), (0, 1));\n",
    "plt.axis('off')\n",
    "plt.title('center camera')\n",
    "plt.imshow(center_img, cmap=\"gray\")\n",
    "\n",
    "plt.subplot2grid((1, 3), (0, 2));\n",
    "plt.axis('off')\n",
    "plt.title('right camera')\n",
    "plt.imshow(right_img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Pre-process the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create training and validation sets *CENTER ONLY*\n",
    "\n",
    "X_train_center = udacity_df.center.tolist()\n",
    "y_train = udacity_df.steering.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "                train_test_split(X_train_center, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "# TODO: Number of validation examples\n",
    "n_valid = len(X_valid)\n",
    "\n",
    "# # TODO: Number of testing examples.\n",
    "# n_test = len(X_test)\n",
    "\n",
    "# # TODO: What's the shape of a traffic sign image?\n",
    "# image_shape = X_train.shape[1:]\n",
    "\n",
    "# # TODO: How many unique classes/labels there are in the dataset.\n",
    "# labels_index = np.unique(y_train)\n",
    "# n_labels = len(labels_index)\n",
    "\n",
    "print(\"Number of training examples: \", n_train)\n",
    "print(\"Number of validation examples: \", n_valid)\n",
    "print(\"----------\\nVerify Totals: {} should equal {} \".format((n_train+n_valid), len(udacity_df)))\n",
    "# print(\"Number of testing examples =\", n_test)\n",
    "# print(\"Image data shape =\", image_shape)\n",
    "# print(\"Number of labels/classes =\", n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# center = udacity_df.center.tolist()\n",
    "# # left = data.left.tolist()\n",
    "# # right = data.right.tolist()\n",
    "# steering = udacity_df.steering.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates batches of tensor image data that is augmented based on a chosen set of tranformation parameters (e.g. rotation, shift, shear, zoom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Apply affine and color transformations \n",
    "\n",
    "# Transformations applied to RBG training images *ORIGINAL from Project 2*\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    zca_whitening=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    channel_shift_range=0.1,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEW augmenation function\n",
    "\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    zca_whitening=True,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    channel_shift_range=0.1,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Architecture\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(images, angles):\n",
    "    images, angles = shuffle(images, angles)\n",
    "    X = []  # images batch\n",
    "    y = []  # angles batch\n",
    "    while True:\n",
    "        for i in range(len(angles)):\n",
    "            img_path = IMG_DIR + images[i]\n",
    "            image = mpimg.imread(img_path.strip())\n",
    "            X.append(image)\n",
    "            y.append(angles[i])\n",
    "            if len(y) == batch_size:\n",
    "                yield (np.array(X), np.array(y))\n",
    "                X, y = ([],[])\n",
    "                images, angles = shuffle(images, angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Global variables and parameters\n",
    "\n",
    "LOG_DIR = \".logs\"\n",
    "MODEL_DIR = \".models\"\n",
    "IMG_DIR = \"data/udacity/\"\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 128\n",
    "\n",
    "mu = 0             # normalized mean\n",
    "sigma = 0.1        # normalized stdev\n",
    "lr = 1e-4          # learning rate\n",
    "reg = l2(1e-5)     # L2 reg\n",
    "drop = 0.5\n",
    "\n",
    "strides = (2, 2)\n",
    "act = 'relu'\n",
    "default_pad = 'same'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape_in = (160, 320, 3)\n",
    "crop = ((70, 26), (0, 0))  # (top, bottom), (left, right)\n",
    "shape_diff = ( (shape_in[0]-(crop[0][0]+crop[0][1])), shape_in[1], shape_in[2] )\n",
    "shape_out = (64, 64 ,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255 - 0.5, input_shape=shape_in))\n",
    "# model.add(Cropping2D(cropping=crop))\n",
    "# model.add(Reshape(shape_out, input_shape=shape_diff))\n",
    "model.add(Convolution2D(24, 5, strides=strides, padding=default_pad, activation=act,  kernel_regularizer=reg))\n",
    "model.add(Convolution2D(36, 5, strides=strides, padding=default_pad, activation=act,  kernel_regularizer=reg))\n",
    "model.add(Convolution2D(48, 5, strides=strides, padding=default_pad, activation=act,  kernel_regularizer=reg))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), padding='valid'))\n",
    "\n",
    "model.add(Convolution2D(64, 3, strides=strides, padding=default_pad, activation=act,  kernel_regularizer=reg))\n",
    "model.add(Convolution2D(64, 3, strides=strides, padding=default_pad, activation=act,  kernel_regularizer=reg))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(80, kernel_regularizer=reg))\n",
    "model.add(Dropout(drop))\n",
    "model.add(Dense(40, kernel_regularizer=reg))\n",
    "model.add(Dropout(drop))\n",
    "model.add(Dense(16, kernel_regularizer=reg))\n",
    "model.add(Dropout(drop))\n",
    "model.add(Dense(10, kernel_regularizer=reg))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile and preview the model\n",
    "model.compile(optimizer=Adam(lr=lr), loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Train and save the model\n",
    "\n",
    "train_gen = generator(X_train, y_train)\n",
    "val_gen = generator(X_valid, y_valid)\n",
    "\n",
    "train_steps = len(X_train) // batch_size\n",
    "val_steps = len(X_valid) // batch_size\n",
    "\n",
    "model.fit_generator(train_gen, steps_per_epoch=train_steps, epochs=epochs, validation_data=val_gen, validation_steps=val_steps)\n",
    "\n",
    "print('\\nDone Training')\n",
    "\n",
    "# Save model and weights\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
